{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c703de9b-9ed4-4b5a-bf05-829fd404365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"EURUSD_tick_OK.csv\"  # Update with the correct path if necessary\n",
    "data = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c05f0-abf0-4ff4-ba84-933334340477",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Normalization (as described in the uploaded file)\n",
    "# Assuming the file has columns like Vol_Ask, Ask, DateDelta1, Bid, Vol_Bid\n",
    "data['Vol_Ask_N'] = c] / 10  # Normalize based on max of 10 lots\n",
    "data['Ask_N'] = (data['Ask'] - data['Ask'].min()) / (data['Ask'].max() - data['Ask'].min())\n",
    "data['DateDelta1_N'] = data['DateDelta1'] / 20000  # Normalize based on max 20 seconds\n",
    "data['Bid_N'] = (data['Bid'] - data['Bid'].min()) / (data['Bid'].max() - data['Bid'].min())\n",
    "data['Vol_Bid_N'] = data['Vol_Bid'] / 10  # Normalize based on max of 10 lots\n",
    "\n",
    "# Create tensors\n",
    "N = 50  # Sequence length\n",
    "n_small = len(data)  # Use the entire dataset size\n",
    "\n",
    "# Convert to NumPy for tensor creation\n",
    "data_normalized = data[['Vol_Ask_N', 'Ask_N', 'DateDelta1_N', 'Bid_N', 'Vol_Bid_N']].values\n",
    "\n",
    "# Create input tensor (X) and output tensor (Y)\n",
    "data_b = np.array([data_normalized[i:i + N] for i in range(n_small - N)])\n",
    "Y = np.array([data_normalized[i + N, [3, 1]] for i in range(n_small - N)])  # Next tick's Bid and Ask\n",
    "\n",
    "# Train-test split\n",
    "train_size = int(0.9 * len(data_b))  # 90% for training\n",
    "X_train, X_test = data_b[:train_size], data_b[train_size:]\n",
    "y_train, y_test = Y[:train_size], Y[train_size:]\n",
    "\n",
    "# Display shapes\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv1D(filters=50, kernel_size=5, activation='relu', input_shape=(50, 5)),\n",
    "    MaxPooling1D(pool_size=7),\n",
    "    Conv1D(filters=100, kernel_size=5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(2)  # Output layer for predicting Bid and Ask prices\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 10  # Calculated based on Z + Y\n",
    "batch_size = 50\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Plot training history\n",
    "history_dict = history.history\n",
    "mean_absolute_error_values = history_dict['mae']\n",
    "val_mean_absolute_error_values = history_dict['val_mae']\n",
    "\n",
    "epochs_range = range(1, len(mean_absolute_error_values) + 1)\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(epochs_range, mean_absolute_error_values, 'bo', label='Training MAE')\n",
    "plt.plot(epochs_range, val_mean_absolute_error_values, 'b', label='Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Absolute Error (MAE)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Generate predictions and compare with true values\n",
    "pred = model.predict(X_test)\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(y_test[:, 0], label='True Bid Prices')\n",
    "plt.plot(pred[:, 0], label='Predicted Bid Prices')\n",
    "plt.title('Bid Price Predictions vs True Values')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(y_test[:, 1], label='True Ask Prices')\n",
    "plt.plot(pred[:, 1], label='Predicted Ask Prices')\n",
    "plt.title('Ask Price Predictions vs True Values')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b590ec5-e6ea-479a-bb4f-6c91daa507b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Vol_Ask_N  Ask_N_200_3  DateDelta1_N  Bid_N_200_3  Vol_Bid_N\n",
      "0      0.176     0.636364       0.01655     0.515152      0.100\n",
      "1      0.364     0.606061       0.02750     0.454545      0.420\n",
      "2      0.100     0.575758       0.09770     0.454545      0.187\n",
      "3      0.100     0.151515       0.01590     0.121212      0.100\n",
      "4      0.270     0.212121       0.01040     0.060606      0.214\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1100000 entries, 0 to 1099999\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count    Dtype  \n",
      "---  ------        --------------    -----  \n",
      " 0   Vol_Ask_N     1100000 non-null  float64\n",
      " 1   Ask_N_200_3   1100000 non-null  float64\n",
      " 2   DateDelta1_N  1100000 non-null  float64\n",
      " 3   Bid_N_200_3   1100000 non-null  float64\n",
      " 4   Vol_Bid_N     1100000 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 42.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display dataset information\n",
    "print(data.head())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "839bedff-6244-43c6-a397-3cb8f37b84a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = 50  # Sequence length\n",
    "n_small = len(data)  # Use the entire dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d00ebc13-4f06-4445-80f0-844881c557ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_normalized = data[['Vol_Ask_N', 'Ask_N_200_3', 'DateDelta1_N', 'Bid_N_200_3', 'Vol_Bid_N']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b5259e2-02c7-4ac2-973b-ef81ce89e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b = np.array([data_normalized[i:i + N] for i in range(n_small - N)])\n",
    "Y = np.array([data_normalized[i + N, [3, 1]] for i in range(n_small - N)])  # Next tick's Bid and Ask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ce66c15-9b7e-4fd2-a2e6-22952d28aea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (989955, 50, 5)\n",
      "y_train shape: (989955, 2)\n",
      "X_test shape: (109995, 50, 5)\n",
      "y_test shape: (109995, 2)\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.9 * len(data_b))  # 90% for training\n",
    "X_train, X_test = data_b[:train_size], data_b[train_size:]\n",
    "y_train, y_test = Y[:train_size], Y[train_size:]\n",
    "\n",
    "# Display shapes\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5569a507-5d39-412a-aa5d-ca75ab15e306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv1D(filters=50, kernel_size=5, activation='relu', input_shape=(50, 5)),\n",
    "    MaxPooling1D(pool_size=7),\n",
    "    Conv1D(filters=100, kernel_size=5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(2)  # Output layer for predicting Bid and Ask prices\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d9a0698-701e-4a50-8a35-63474770baf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m19800/19800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 0.0069 - mae: 0.0600 - val_loss: 0.0052 - val_mae: 0.0527\n",
      "Epoch 2/10\n",
      "\u001b[1m19800/19800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 0.0052 - mae: 0.0524 - val_loss: 0.0051 - val_mae: 0.0521\n",
      "Epoch 3/10\n",
      "\u001b[1m19800/19800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0051 - mae: 0.0517 - val_loss: 0.0050 - val_mae: 0.0507\n",
      "Epoch 4/10\n",
      "\u001b[1m19800/19800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0050 - mae: 0.0511 - val_loss: 0.0063 - val_mae: 0.0593\n",
      "Epoch 5/10\n",
      "\u001b[1m19800/19800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0050 - mae: 0.0510 - val_loss: 0.0049 - val_mae: 0.0508\n",
      "Epoch 6/10\n",
      "\u001b[1m19800/19800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0049 - mae: 0.0508 - val_loss: 0.0050 - val_mae: 0.0509\n",
      "Epoch 7/10\n",
      "\u001b[1m19800/19800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0049 - mae: 0.0506 - val_loss: 0.0050 - val_mae: 0.0509\n",
      "Epoch 8/10\n",
      "\u001b[1m19800/19800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0049 - mae: 0.0505 - val_loss: 0.0049 - val_mae: 0.0504\n",
      "Epoch 9/10\n",
      "\u001b[1m19800/19800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0049 - mae: 0.0503 - val_loss: 0.0049 - val_mae: 0.0504\n",
      "Epoch 10/10\n",
      "\u001b[1m19800/19800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 0.0048 - mae: 0.0502 - val_loss: 0.0050 - val_mae: 0.0507\n"
     ]
    }
   ],
   "source": [
    "epochs = 10 \n",
    "batch_size = 50\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d73f24-94b3-433f-87af-d3e9b30307db",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Mean Absolute Error (MAE): {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a04003e-1812-4c03-96b1-e3ca1c493f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "mean_absolute_error_values = history_dict['mae']\n",
    "val_mean_absolute_error_values = history_dict['val_mae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9728fb1a-5007-4bd3-939d-d83d6e485fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(1, len(mean_absolute_error_values) + 1)\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(epochs_range, mean_absolute_error_values, 'bo', label='Training MAE')\n",
    "plt.plot(epochs_range, val_mean_absolute_error_values, 'b', label='Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Absolute Error (MAE)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c8bc36-01cc-48d7-aea3-502d38b9a3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(y_test[:, 0], label='True Bid Prices')\n",
    "plt.plot(pred[:, 0], label='Predicted Bid Prices')\n",
    "plt.title('Bid Price Predictions vs True Values')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(y_test[:, 1], label='True Ask Prices')\n",
    "plt.plot(pred[:, 1], label='Predicted Ask Prices')\n",
    "plt.title('Ask Price Predictions vs True Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
